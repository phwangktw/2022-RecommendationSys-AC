{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session2_Content-based_Recommendation_Algorithm.ipynb.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOayUTfl3miZ677FoCU1E2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phwangktw/data-course-sample/blob/main/Session2_Content_based_Recommendation_Algorithm_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session2: Content-based Recommendation Algorithm"
      ],
      "metadata": {
        "id": "Yz-rghKTyqwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1. Load data"
      ],
      "metadata": {
        "id": "h7dsDP9Xyv4K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7UjSP35yo4j",
        "outputId": "8f56bff8-0be3-4177-8a07-3b370fe5b477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gzip, json\n",
        "from os.path import exists\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import datetime\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "def parse(path):\n",
        "    g = gzip.open(path, 'rb')\n",
        "    for l in g:\n",
        "        yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "    i = 0\n",
        "    df = {}\n",
        "    for d in parse(path):\n",
        "        df[i] = d\n",
        "        i += 1\n",
        "    return pd.DataFrame.from_dict(df, orient='index')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "def content_filter(text):\n",
        "    # stopwords = nltk.corpus.stopwords.words('english')\n",
        "    content = [w for w in text if (w.lower() not in stop_words) & (w.isalnum()) ]\n",
        "    return content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2. Download data"
      ],
      "metadata": {
        "id": "WhNHwYPky2V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv\n",
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_All_Beauty.json.gz\n",
        "\n",
        "metadata = getDF('/content/meta_All_Beauty.json.gz')\n",
        "ratings = pd.read_csv('/content/All_Beauty.csv', names=['asin', 'reviewerID', 'overall', 'unixReviewTime'], header=None)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrM-TOz6y2nx",
        "outputId": "f83f3db9-3129-4942-8b45-36c923e5ee9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-02 06:39:57--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15499476 (15M) [application/octet-stream]\n",
            "Saving to: ‘All_Beauty.csv.3’\n",
            "\n",
            "All_Beauty.csv.3    100%[===================>]  14.78M  22.2MB/s    in 0.7s    \n",
            "\n",
            "2022-01-02 06:39:58 (22.2 MB/s) - ‘All_Beauty.csv.3’ saved [15499476/15499476]\n",
            "\n",
            "--2022-01-02 06:39:58--  http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_All_Beauty.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10329961 (9.9M) [application/octet-stream]\n",
            "Saving to: ‘meta_All_Beauty.json.gz.3’\n",
            "\n",
            "meta_All_Beauty.jso 100%[===================>]   9.85M  18.7MB/s    in 0.5s    \n",
            "\n",
            "2022-01-02 06:39:59 (18.7 MB/s) - ‘meta_All_Beauty.json.gz.3’ saved [10329961/10329961]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3. Parsing data"
      ],
      "metadata": {
        "id": "cyt6lpHCzKu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-1: Convert time format"
      ],
      "metadata": {
        "id": "234dDW6TzOnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings['DATE'] = pd.to_datetime(ratings['unixReviewTime'], unit='s')"
      ],
      "metadata": {
        "id": "R2gHgYvNzLAq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-2: Data preprocessing\n",
        "\n",
        "\n",
        "*   Dropout the duplicated rows\n",
        "*   Fill the blanks with `nan`\n",
        "*   Parsing the `description` column for generating `rank_num` and `rank_category`\n",
        "*   Regex expression for searching specific key words"
      ],
      "metadata": {
        "id": "hQepuRY9zTAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Cleaning data (cited from: https://github.com/yuchiahung/data-course-sample/blob/main/hw1_Ana.ipynb)\n",
        "##Peaking data firstly\n",
        "metadata_clean = metadata.loc[metadata.astype(str).drop_duplicates().index]\n",
        "metadata_clean.replace('', np.nan, inplace = True)\n",
        "\n",
        "\n",
        "# clean column `rank` -> Parsing out to RankNum + RankCategory\n",
        "metadata_clean['rank'] = metadata_clean['rank'].str.replace('&amp;', '&')\n",
        "metadata_clean['rank'].fillna('0', inplace = True)\n",
        "metadata_clean['rank_category'] = [re.search('in (.*) \\(', r).group(1) if r != '0' else None for r in metadata_clean['rank']]\n",
        "metadata_clean['rank_num'] = [re.search('(.*) in .*', r).group(1) if r != '0' else None for r in metadata_clean['rank']]\n",
        "metadata_clean['rank_num'] = metadata_clean['rank_num'].str.replace(',', '').astype(float)\n",
        "\n",
        "# excluding category != 'Beauty & Personal Care'\n",
        "metadata_clean = metadata_clean[metadata_clean.rank_category == 'Beauty & Personal Care']\n",
        "\n",
        "# convert `price` to float\n",
        "metadata_clean['price'].fillna('0', inplace = True)\n",
        "metadata_clean['price'] = [re.search('\\$(.*)', p).group(1) if re.search('\\$(.*)', p) != None else None for p in metadata_clean['price']]\n",
        "metadata_clean['price'] = metadata_clean['price'].str.replace(',', '').astype(float)\n",
        "\n",
        "# drop useless columns\n",
        "metadata_clean.drop(\n",
        "    ['category', 'tech1', 'fit', 'tech2', 'date', 'similar_item', 'feature', 'main_cat', 'rank'], \n",
        "    axis = 1, \n",
        "    inplace = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If7B5QErzLP6",
        "outputId": "1de896bd-11f2-4716-c546-2cf0b166465a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find out top X frequency of the words"
      ],
      "metadata": {
        "id": "RSon2t4KGoU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_titleOnly = metadata_clean[['asin','title']].reset_index().drop(['index'], axis=1)\n",
        "metadata_titleOnly['title'] = metadata_titleOnly['title'].str.replace('&amp;', '')\n",
        "wholeContent = ''\n",
        "for i, a in enumerate(metadata_titleOnly.title):\n",
        "    wholeContent += a + ' '\n",
        "\n",
        "##TODO: filter out the numerical words (Ex. 8, 24...)\n",
        "tokens = nltk.word_tokenize(wholeContent)\n",
        "contentToken_filtered = content_filter(tokens)\n",
        "rawBgs = nltk.ngrams(contentToken_filtered,1)\n",
        "fdist = nltk.FreqDist(rawBgs)\n",
        "\n",
        "keywordlist ={}\n",
        "for k, v in fdist.items():                  \n",
        "    keywordlist[k[0]] = v\n",
        "\n",
        "#Check only\n",
        "CountsDF = pd.DataFrame.from_dict(keywordlist, orient='index',columns=['Counts'])\n",
        "#Control size of the keywords\n",
        "filterList = CountsDF.reset_index().rename(columns={'index': 'word'}).sort_values('Counts',ascending=False).head(20000).word.tolist()\n",
        "CountsDF.describe()\n",
        "thrhold = CountsDF.Counts.quantile(0.9)"
      ],
      "metadata": {
        "id": "J9huCMwwGoBn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 123"
      ],
      "metadata": {
        "id": "6sc1GD9AG5k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Parsing\n",
        "#Step1: Parsing title to KeyWords ONLY\n",
        "keyCounts = 0\n",
        "metadata_titleOnly['titleNew'] = \"\"\n",
        "for i, a in enumerate(metadata_titleOnly.title):\n",
        "    a_Raw = a.split()\n",
        "    resultwords  = [word for word in a_Raw if word.lower() in filterList]\n",
        "    result = ' '.join(resultwords)    \n",
        "    if (len(result) != 0):\n",
        "        metadata_titleOnly.loc[i, 'titleNew'] = result\n",
        "        keyCounts += 1\n",
        "\n",
        "keyWordCoverage = keyCounts/metadata_titleOnly.shape[0]\n",
        "print(f'Key words coverage: {round(keyWordCoverage, 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lqu2o8iG5W2",
        "outputId": "7f0cdbb9-6051-4bb4-bd8b-6e01b78954e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key words coverage: 0.9828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算商品用標題所表示的 tfidf 矩陣\n",
        "#df_test = metadata_titleOnly.drop_duplicates('titleNew')\n",
        "#If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
        "#Only applies if analyzer == 'word'.\n",
        "tf = TfidfVectorizer(analyzer='word')\n",
        "tfidf_matrix = tf.fit_transform(metadata_titleOnly['titleNew'])\n",
        "\n",
        "# 計算商品間的相似程度\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "mapping = pd.Series(metadata_titleOnly.index,index = metadata_titleOnly['asin'])\n",
        "\n",
        "# 每個商品回傳 k 個最相近的商品\n",
        "def recommend_item(item_input, k):\n",
        "    try:\n",
        "        item_index = mapping[item_input]\n",
        "        similarity_score = list(enumerate(similarity_matrix[item_index]))\n",
        "        similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
        "        similarity_score = similarity_score[:k]\n",
        "        item_indices = [i[0] for i in similarity_score]\n",
        "        return (metadata_titleOnly['asin'].iloc[item_indices].tolist())\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "# 利用使用者購買過的商品產生推薦 (KNN average the purchase history)\n",
        "def recommend_items(items, k):\n",
        "    res = []\n",
        "    for d in items:\n",
        "        res.extend(recommend_item(d, k))\n",
        "    return res"
      ],
      "metadata": {
        "id": "T5Oca1_AHDKy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-3: Split time frame for testing and validation purpose\n",
        "\n",
        "\n",
        "*   Visualize the distribution of sales on the time axis"
      ],
      "metadata": {
        "id": "haPjtQk3zaRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_trainings = ratings[\n",
        "    (ratings['DATE'] < '2018-09-01')\n",
        "]\n",
        "ratings_testings = ratings[\n",
        "    (ratings['DATE'] >= '2018-09-01') & \n",
        "    (ratings['DATE'] <= '2018-09-30')\n",
        "]\n",
        "ratings_testings_by_user = ratings_testings.groupby('reviewerID').agg(list).reset_index()[['reviewerID', 'asin']].to_dict('records')\n",
        "ratings_testings_by_user = { rating['reviewerID']: rating['asin'] for rating in ratings_testings_by_user }\n",
        "users = list(ratings_testings_by_user.keys())"
      ],
      "metadata": {
        "id": "Z_EvEzeszLfO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommender_content1(training_data, users=[], k=10):\n",
        "    '''\n",
        "    * training_data: dataframe 輸入的訓練資料集（2018-09-01 以前資料）\n",
        "    * users: [] 需要被推薦的使用者\n",
        "    * k: int 每個使用者需要推薦的商品數\n",
        "    * recommendations: dict\n",
        "      {\n",
        "          使用者一： [推薦商品一, 推薦商品二, ...],\n",
        "          使用者二： [...], ...\n",
        "      }\n",
        "    '''\n",
        "    recommendations = {}\n",
        "       \n",
        "    for user in users:\n",
        "        content_recom = []\n",
        "        rule_recom = []\n",
        "        k1 = 5\n",
        "        ### UserID convert to purchase history\n",
        "        ## Content-based \n",
        "        ### Ensure the user has existing purchase (comment) history\n",
        "        existHistory = metadata[metadata['asin'].isin(ratings_trainings[ratings_trainings['reviewerID'] == user]['asin'].tolist())]['asin'].tolist()\n",
        "        if len(existHistory) > 0:\n",
        "            content_recom = recommend_items(existHistory,k1)\n",
        "        \n",
        "        # Popular products (recommend `k_left` products)\n",
        "        k_left = k - len(content_recom)\n",
        "        ## Best seller (by rating data) & highest rating products (recommend `k` product)\n",
        "        products_rating = training_data[training_data.DATE >= '2017-09-01'].groupby('asin')[['overall']].agg(['mean', 'count'])\n",
        "        products_rating.columns = products_rating.columns.droplevel(0)\n",
        "        rule_recom = products_rating.sort_values(by = ['count', 'mean'], ascending = False).index.tolist()[:k_left]\n",
        "        \n",
        "        \n",
        "        # concat all the item lists (k2 by rank, k3 by rating, others by sales)\n",
        "        user_recom = content_recom + rule_recom\n",
        "        recommendations[user] = user_recom\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "dXFFg_xtIgj8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(ratings_testings_by_user={}, ratings_by_user={}, method=None):\n",
        "    '''\n",
        "    * ratings_testings_by_user: dict 真實被購買的商品資料（2018-09-01 以後資料）\n",
        "    * ratings_by_user: dict 利用訓練資料學習的推薦商品\n",
        "    * method: str\n",
        "    * score: float\n",
        "    '''\n",
        "    total = 0\n",
        "    for d in ratings_testings_by_user:\n",
        "        if d in ratings_by_user:\n",
        "            total += len(set(ratings_by_user[d]) & set(ratings_testings_by_user[d]))\n",
        "\n",
        "    score = total / len(ratings_testings)\n",
        "    return score\n",
        "\n",
        "rcListRule1 = recommender_content1(ratings_trainings, users)\n",
        "# Evaluation scores\n",
        "print(f'Rule1: \\n{round(evaluate(ratings_testings_by_user, rcListRule1), 4)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhUWZ2gjPRlR",
        "outputId": "62de80df-176c-4858-89dc-ed16746fa842"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule1: \n",
            "0.1051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "userWithHistory = []\n",
        "for user in users:\n",
        "    existHistory = metadata[metadata['asin'].isin(ratings_trainings[ratings_trainings['reviewerID'] == user]['asin'].tolist())]['asin'].tolist()\n",
        "    if len(existHistory) != 0:\n",
        "        userWithHistory.append(user)\n",
        "userWithHistoryAns = {}\n",
        "for i in range(len(userWithHistory)):\n",
        "  userWithHistoryAns[userWithHistory[i]] = ratings_testings_by_user[userWithHistory[i]]"
      ],
      "metadata": {
        "id": "CLrL1lqfZSPi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rcListRule2 = recommender_content1(ratings_trainings, userWithHistory)\n",
        "# Evaluation scores\n",
        "print(f'Rule1: \\n{round(evaluate(userWithHistoryAns, rcListRule2), 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVDACTBHbZno",
        "outputId": "0f782583-87a5-4454-ab6d-fde2a3de3afd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule1: \n",
            "0.0102\n"
          ]
        }
      ]
    }
  ]
}