{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session2_Content-based_Recommendation_Algorithm.ipynb.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/phwangktw/data-course-sample/blob/main/Session2_Content_based_Recommendation_Algorithm_ipynb.ipynb",
      "authorship_tag": "ABX9TyNJ2k4XmrWj0GuAjFG2vYq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phwangktw/data-course-sample/blob/main/Session3_Collaborative-based(item-based)_Recommendation_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session3_Collaborative-based(item-based)_Recommendation_Algorithm.ipynb"
      ],
      "metadata": {
        "id": "Yz-rghKTyqwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1. Packages import and utiltiets functions\n",
        "\n",
        "*   `nltk` package used for text parsing.\n",
        "\n"
      ],
      "metadata": {
        "id": "h7dsDP9Xyv4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hai9bqC5q1SL",
        "outputId": "98b7be5b-3ff6-4561-ea88-98509dd8d48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7UjSP35yo4j",
        "outputId": "e7728e4b-4613-42f3-8ec7-dfe041f37e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gzip, json\n",
        "from os.path import exists\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import datetime\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "def parse(path):\n",
        "    g = gzip.open(path, 'rb')\n",
        "    for l in g:\n",
        "        yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "    i = 0\n",
        "    df = {}\n",
        "    for d in parse(path):\n",
        "        df[i] = d\n",
        "        i += 1\n",
        "    return pd.DataFrame.from_dict(df, orient='index')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "def content_filter(text):\n",
        "    # stopwords = nltk.corpus.stopwords.words('english')\n",
        "    content = [w for w in text if (w.lower() not in stop_words) & (w.isalnum()) ]\n",
        "    return content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2. Download data"
      ],
      "metadata": {
        "id": "WhNHwYPky2V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv\n",
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_All_Beauty.json.gz\n",
        "\n",
        "metadata = getDF('/content/meta_All_Beauty.json.gz')\n",
        "ratings = pd.read_csv('/content/All_Beauty.csv', names=['asin', 'reviewerID', 'overall', 'unixReviewTime'], header=None)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrM-TOz6y2nx",
        "outputId": "2d8332da-bb1d-4304-a66b-921316bdc473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-03 20:30:49--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15499476 (15M) [application/octet-stream]\n",
            "Saving to: ‘All_Beauty.csv’\n",
            "\n",
            "All_Beauty.csv      100%[===================>]  14.78M  8.16MB/s    in 1.8s    \n",
            "\n",
            "2022-01-03 20:30:51 (8.16 MB/s) - ‘All_Beauty.csv’ saved [15499476/15499476]\n",
            "\n",
            "--2022-01-03 20:30:51--  http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_All_Beauty.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10329961 (9.9M) [application/octet-stream]\n",
            "Saving to: ‘meta_All_Beauty.json.gz’\n",
            "\n",
            "meta_All_Beauty.jso 100%[===================>]   9.85M  6.02MB/s    in 1.6s    \n",
            "\n",
            "2022-01-03 20:30:53 (6.02 MB/s) - ‘meta_All_Beauty.json.gz’ saved [10329961/10329961]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3. Parsing data"
      ],
      "metadata": {
        "id": "cyt6lpHCzKu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-1: Convert time format"
      ],
      "metadata": {
        "id": "234dDW6TzOnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings['DATE'] = pd.to_datetime(ratings['unixReviewTime'], unit='s')"
      ],
      "metadata": {
        "id": "R2gHgYvNzLAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-2: Data preprocessing\n",
        "(As same as [session1](https://github.com/phwangktw/data-course-sample/blob/main/Session1_Rule-based_Recommendation_Algorithm.ipynb))\n",
        "\n",
        "*   Dropout the duplicated rows\n",
        "*   Fill the blanks with `nan`\n",
        "*   Parsing the `description` column for generating `rank_num` and `rank_category`\n",
        "*   Regex expression for searching specific key words"
      ],
      "metadata": {
        "id": "hQepuRY9zTAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Cleaning data (cited from: https://github.com/yuchiahung/data-course-sample/blob/main/hw1_Ana.ipynb)\n",
        "##Peaking data firstly\n",
        "metadata_clean = metadata.loc[metadata.astype(str).drop_duplicates().index]\n",
        "metadata_clean.replace('', np.nan, inplace = True)\n",
        "\n",
        "\n",
        "# clean column `rank` -> Parsing out to RankNum + RankCategory\n",
        "metadata_clean['rank'] = metadata_clean['rank'].str.replace('&amp;', '&')\n",
        "metadata_clean['rank'].fillna('0', inplace = True)\n",
        "metadata_clean['rank_category'] = [re.search('in (.*) \\(', r).group(1) if r != '0' else None for r in metadata_clean['rank']]\n",
        "metadata_clean['rank_num'] = [re.search('(.*) in .*', r).group(1) if r != '0' else None for r in metadata_clean['rank']]\n",
        "metadata_clean['rank_num'] = metadata_clean['rank_num'].str.replace(',', '').astype(float)\n",
        "\n",
        "# excluding category != 'Beauty & Personal Care'\n",
        "metadata_clean = metadata_clean[metadata_clean.rank_category == 'Beauty & Personal Care']\n",
        "\n",
        "# convert `price` to float\n",
        "metadata_clean['price'].fillna('0', inplace = True)\n",
        "metadata_clean['price'] = [re.search('\\$(.*)', p).group(1) if re.search('\\$(.*)', p) != None else None for p in metadata_clean['price']]\n",
        "metadata_clean['price'] = metadata_clean['price'].str.replace(',', '').astype(float)\n",
        "\n",
        "# drop useless columns\n",
        "metadata_clean.drop(\n",
        "    ['category', 'tech1', 'fit', 'tech2', 'date', 'similar_item', 'feature', 'main_cat', 'rank'], \n",
        "    axis = 1, \n",
        "    inplace = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If7B5QErzLP6",
        "outputId": "24d20ce9-03f6-4391-a0a0-20fa6f867a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-3: Analyze the distribution of the words\n",
        "*   Problem statement:"
      ],
      "metadata": {
        "id": "RSon2t4KGoU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZgBgK9w4ra3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-4: Text Parsing\n"
      ],
      "metadata": {
        "id": "6sc1GD9AG5k_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "99.74% of the products will \"at least have 1 value\" in the vectorized text vector. Although some of the information might be lost, the gain of the computational resource is more beneficial."
      ],
      "metadata": {
        "id": "DwiHZpdkyLpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-5: TF-IDF Matrix Generation\n",
        "- csr_matrix() (Compressed Sparse Row Matrix): `TfidfVectorizer` is used for TF-IDF generation.\n",
        "  "
      ],
      "metadata": {
        "id": "rWBj8XgA_odW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-6: Similarity Calculation (based on cosine_similarity)\n",
        "\n",
        "#### Example1:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cU5_uYNBA3UH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4: Algorithm Model Implementation\n",
        "### Step4-1: Details of the content-based algorithm \n",
        "\n",
        "\n",
        "*   Step1: Iteratively examines the recommended items with respect to each history of purchased items.\n",
        "*   Step2: Generate topK items with the highest similarity score.\n",
        "\n"
      ],
      "metadata": {
        "id": "0kRtB6NvQ4fW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step4-2: Split time frame for testing and validation purpose"
      ],
      "metadata": {
        "id": "haPjtQk3zaRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_trainings = ratings[\n",
        "    (ratings['DATE'] < '2018-09-01')\n",
        "]\n",
        "ratings_testings = ratings[\n",
        "    (ratings['DATE'] >= '2018-09-01') & \n",
        "    (ratings['DATE'] <= '2018-09-30')\n",
        "]\n",
        "ratings_testings_by_user = ratings_testings.groupby('reviewerID').agg(list).reset_index()[['reviewerID', 'asin']].to_dict('records')\n",
        "ratings_testings_by_user = { rating['reviewerID']: rating['asin'] for rating in ratings_testings_by_user }\n",
        "users = list(ratings_testings_by_user.keys())"
      ],
      "metadata": {
        "id": "Z_EvEzeszLfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "\n",
        "def recommender(training_data, users=[], k=10):\n",
        "\n",
        "    # loading data from dataframe\n",
        "    # item_to_users dict:\n",
        "    # {\n",
        "    #   'item': {\n",
        "    #       'user': ratings...\n",
        "    #   }...\n",
        "    # }\n",
        "    item_to_users = defaultdict(dict)\n",
        "    for _, row in training_data.iterrows():\n",
        "        row = dict(row)\n",
        "        user = row['reviewerID']\n",
        "        item = row['asin']\n",
        "        rating = float(row['overall'])\n",
        "        item_to_users[item][user] = rating\n",
        "\n",
        "    print(\"data converted\")\n",
        "\n",
        "    user_to_items = defaultdict(dict)\n",
        "    for item, rating_users in item_to_users.items():\n",
        "        for user, rating in rating_users.items():\n",
        "            user_to_items[user][item] = rating\n",
        "\n",
        "    print(\"data inverted\")\n",
        "\n",
        "    init_sim = lambda: [0, 0, 0]\n",
        "    factory = lambda: defaultdict(init_sim)\n",
        "    pre_item_similarity = defaultdict(factory)\n",
        "    for user, items in user_to_items.items():\n",
        "        if len(items) > 1:\n",
        "            for i1, i2 in combinations(items.keys(), 2):\n",
        "                xy = items[i1] * items[i2]\n",
        "                xx = items[i1] ** 2\n",
        "                yy = items[i2] ** 2\n",
        "                pre_item_similarity[i1][i2][0] += xy\n",
        "                pre_item_similarity[i1][i2][1] += xx\n",
        "                pre_item_similarity[i1][i2][2] += yy\n",
        "\n",
        "                pre_item_similarity[i2][i1][0] += xy\n",
        "                pre_item_similarity[i2][i1][1] += xx\n",
        "                pre_item_similarity[i2][i1][2] += yy\n",
        "\n",
        "    print(\"sim data prepared\")\n",
        "\n",
        "    item_similarity = {}\n",
        "    for src_item in pre_item_similarity:\n",
        "        item_similarity_order = []\n",
        "        for dst_item, val in pre_item_similarity[src_item].items():\n",
        "            xy = val[0]\n",
        "            xx = val[1]\n",
        "            yy = val[2]\n",
        "            div = ((xx*yy) ** 0.5)\n",
        "            if div == 0:\n",
        "                continue\n",
        "            similarity = xy / div\n",
        "            if similarity < 0:\n",
        "                continue\n",
        "            for i, s in enumerate(item_similarity_order):\n",
        "                target_similarity = s[1]\n",
        "                if target_similarity < similarity:\n",
        "                    item_similarity_order.insert(i, (dst_item, similarity))\n",
        "                    break\n",
        "            else:\n",
        "                item_similarity_order.append((dst_item, similarity))\n",
        "        item_similarity[src_item] = item_similarity_order\n",
        "\n",
        "    print(f\"get {k} recommendation items for for user: {users}\")\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items = []\n",
        "        items_set = set()\n",
        "        stop = False\n",
        "        user_has_rated = set(user_to_items[user])\n",
        "        for item in user_has_rated:\n",
        "            if item in item_similarity:\n",
        "                for sim_item, _ in item_similarity[item]:\n",
        "                    # skip the item user has rated\n",
        "                    if sim_item not in user_has_rated and sim_item not in items_set:\n",
        "                        items.append(sim_item)\n",
        "                        items_set.add(sim_item)\n",
        "                    if len(items) >= k:\n",
        "                        stop = True\n",
        "                        break\n",
        "                if stop:\n",
        "                    break\n",
        "        recommendation[user] = items\n",
        "    return recommendation    \n",
        "\n",
        "ratings_by_user = recommender(ratings_trainings, users)\n",
        "ratings_by_user"
      ],
      "metadata": {
        "id": "bFUl_TUc9hqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step4-3: Content-based Model setup \n",
        "\n",
        "\n",
        "*   Stpe1: Set a fixed number (`k1=5`) for the content-based recommendation, and others for the rule-based recommendation.\n",
        "*   Step2: Examine the user whether or not the history purchases exist.\n",
        "*   Step3: Combine both content-based and rule-based results as the users' recommendations.\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "3C5DACT8P1YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommender_content1(training_data, users=[], k=10):\n",
        "    '''\n",
        "    * training_data: dataframe 輸入的訓練資料集（2018-09-01 以前資料）\n",
        "    * users: [] 需要被推薦的使用者\n",
        "    * k: int 每個使用者需要推薦的商品數\n",
        "    * recommendations: dict\n",
        "      {\n",
        "          使用者一： [推薦商品一, 推薦商品二, ...],\n",
        "          使用者二： [...], ...\n",
        "      }\n",
        "    '''\n",
        "    recommendations = {}\n",
        "       \n",
        "    for user in users:\n",
        "        content_recom = []\n",
        "        rule_recom = []\n",
        "        k1 = 5\n",
        "        ### UserID convert to purchase history\n",
        "        ## Content-based \n",
        "        ### Ensure the user has existing purchase (comment) history\n",
        "        existHistory = metadata[metadata['asin'].isin(ratings_trainings[ratings_trainings['reviewerID'] == user]['asin'].tolist())]['asin'].tolist()\n",
        "        if len(existHistory) > 0:\n",
        "            content_recom = recommend_items(existHistory,k1)\n",
        "        \n",
        "        # Popular products (recommend `k_left` products)\n",
        "        k_left = k - len(content_recom)\n",
        "        ## Best seller (by rating data) & highest rating products (recommend `k` product)\n",
        "        products_rating = training_data[training_data.DATE >= '2017-09-01'].groupby('asin')[['overall']].agg(['mean', 'count'])\n",
        "        products_rating.columns = products_rating.columns.droplevel(0)\n",
        "        rule_recom = products_rating.sort_values(by = ['count', 'mean'], ascending = False).index.tolist()[:k_left]\n",
        "        \n",
        "        \n",
        "        # concat all the item lists (k2 by rank, k3 by rating, others by sales)\n",
        "        user_recom = content_recom + rule_recom\n",
        "        recommendations[user] = user_recom\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "dXFFg_xtIgj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step4-4: Base Model setup \n",
        "Base case setup as the rule-based algorithm of the most K popular products of the recent year (see as Session1). "
      ],
      "metadata": {
        "id": "P_JbJOsuPUpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rule1: A year-based recommendation\n",
        "def recommender_base(training_data, users=[], k=10):\n",
        "    '''\n",
        "    * training_data: dataframe 輸入的訓練資料集（2018-09-01 以前資料）\n",
        "    * users: [] 需要被推薦的使用者\n",
        "    * k: int 每個使用者需要推薦的商品數\n",
        "    * recommendations: dict\n",
        "      {\n",
        "          使用者一： [推薦商品一, 推薦商品二, ...],\n",
        "          使用者二： [...], ...\n",
        "      }\n",
        "    '''\n",
        "    recommendations = {}\n",
        "    ## Best seller (by rating data) & highest rating products (recommend `k` product)\n",
        "    products_rating = training_data[training_data.DATE >= '2017-09-01'].groupby('asin')[['overall']].agg(['mean', 'count'])\n",
        "    products_rating.columns = products_rating.columns.droplevel(0)\n",
        "    best_seller_lst = products_rating.sort_values(by = ['count', 'mean'], ascending = False).index.tolist()[:k]\n",
        "\n",
        "    recommendations = {user: best_seller_lst for user in users}\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "Jy_4X86r9J8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step4-5: Evaluation Algorithm and the Results"
      ],
      "metadata": {
        "id": "aboqSGJfVBuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(ratings_testings_by_user={}, ratings_by_user={}, method=None):\n",
        "    '''\n",
        "    * ratings_testings_by_user: dict 真實被購買的商品資料（2018-09-01 以後資料）\n",
        "    * ratings_by_user: dict 利用訓練資料學習的推薦商品\n",
        "    * method: str\n",
        "    * score: float\n",
        "    '''\n",
        "    total = 0\n",
        "    for d in ratings_testings_by_user:\n",
        "        if d in ratings_by_user:\n",
        "            total += len(set(ratings_by_user[d]) & set(ratings_testings_by_user[d]))\n",
        "\n",
        "    score = total / len(ratings_testings)\n",
        "    return score\n",
        "\n",
        "rcListRule1 = recommender_content1(ratings_trainings, users)\n",
        "rcListBase = recommender_base(ratings_trainings, users)\n",
        "\n",
        "scoreContent = evaluate(ratings_testings_by_user, rcListRule1)\n",
        "scoreBase = evaluate(ratings_testings_by_user, rcListBase)\n",
        "# Evaluation scores\n",
        "print(f'Rule1: \\n{round(scoreContent, 4)}')\n",
        "print(f'Base_case: \\n{round(scoreBase, 4)}')\n",
        "print(f'Improvemnt of Content-based method: \\n{round(100*(scoreContent-scoreBase)/scoreContent, 1)} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhUWZ2gjPRlR",
        "outputId": "7ae7678c-1b84-4442-b2d7-2b215ac78da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule1: \n",
            "0.1068\n",
            "Base_case: \n",
            "0.0983\n",
            "Improvemnt of Content-based method: \n",
            "7.9 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5: Discussions of obstacles\n",
        "\n",
        "The reasons that we cannot generate significant score improvements are described as follows:\n",
        "*   55555\n"
      ],
      "metadata": {
        "id": "sED9o2in_Lqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userWithHistory = []\n",
        "for user in users:\n",
        "    existHistory = metadata[metadata['asin'].isin(ratings_trainings[ratings_trainings['reviewerID'] == user]['asin'].tolist())]['asin'].tolist()\n",
        "    if len(existHistory) != 0:\n",
        "        userWithHistory.append(user)\n",
        "userWithHistoryAns = {}\n",
        "for i in range(len(userWithHistory)):\n",
        "  userWithHistoryAns[userWithHistory[i]] = ratings_testings_by_user[userWithHistory[i]]"
      ],
      "metadata": {
        "id": "CLrL1lqfZSPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rcListRule2 = recommender_content1(ratings_trainings, userWithHistory)\n",
        "# Evaluation scores\n",
        "print(f'Rule1: \\n{round(evaluate(userWithHistoryAns, rcListRule2), 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVDACTBHbZno",
        "outputId": "2cce361a-ffc7-4cc2-d490-d563f8947d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule1: \n",
            "0.0119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_item(item_input, k=2):\n",
        "    try:\n",
        "        item_index = mapping[item_input]\n",
        "        similarity_score = list(enumerate(similarity_matrix[item_index]))\n",
        "        similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
        "        similarity_score = similarity_score[:k]\n",
        "        item_indices = [i[0] for i in similarity_score]\n",
        "        return (metadata_titleOnly['asin'].iloc[item_indices].tolist())\n",
        "    except:\n",
        "        return []"
      ],
      "metadata": {
        "id": "SjdEfG54GtNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_item_lookup(item_input, item_ans):\n",
        "    try:\n",
        "        resultString = ''\n",
        "        item_index = mapping[item_input]\n",
        "        item_ans_index = mapping[item_ans]\n",
        "        similarity_score = list(enumerate(similarity_matrix[item_index]))\n",
        "        similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
        "        i_rank = 0\n",
        "        while (item_ans_index != similarity_score[i_rank][0]):\n",
        "            i_rank +=1\n",
        "            \n",
        "        resultString = 'Acual bought item is ranked as: '+str(i_rank)+' with score: '+str(round(similarity_score[i_rank][1],4))\n",
        "        return resultString\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "testUsers = ['A1UAOE8KO7Q1DZ', 'A1WEFBEJ7OHSVZ', 'A1WSZED2O5MA5T', 'A28E3FNV1BYC94', 'A29834GBB4DOP1']\n",
        "for user in testUsers:\n",
        "    asin2titleNew = []\n",
        "    actualtitleNew = []\n",
        "    existHistory = metadata[metadata['asin'].isin(ratings_trainings[ratings_trainings['reviewerID'] == user]['asin'].tolist())]['asin'].tolist()\n",
        "\n",
        "    for historyItem in existHistory:\n",
        "        asin2titleNew.append(metadata_titleOnly[metadata_titleOnly['asin']==historyItem]['title'].iloc[0])\n",
        "        realBoughtList = userWithHistoryAns[user]\n",
        "        for realBoughtItem in realBoughtList:\n",
        "            actualtitleNew.append(metadata_titleOnly[metadata_titleOnly['asin']==realBoughtItem]['title'].iloc[0])\n",
        "            resultStr = recommend_item_lookup(historyItem, realBoughtItem)\n",
        "    for j in asin2titleNew:\n",
        "        print('\\n'+user+' once bought: '+j)\n",
        "    for k in actualtitleNew:\n",
        "        print('\\n'+user+' now bought: '+k)\n",
        "    print('\\n'+resultStr)\n",
        "    print('------------------------------')"
      ],
      "metadata": {
        "id": "BgJ4mL7nF9pk",
        "outputId": "2b338853-7965-402e-d674-92aa9481eddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A1UAOE8KO7Q1DZ once bought: H2O+ Sea Salt Hydrating Body Lotion - 250ml/8.5oz\n",
            "\n",
            "A1UAOE8KO7Q1DZ now bought: Algenist Genius Ultimate Anti-Aging Eye Cream w/ Alguronic Acid (.17 oz) Mini Travel Size\n",
            "\n",
            "Acual bought item is ranked as: 29267 with score: 0.0\n",
            "------------------------------\n",
            "\n",
            "A1WEFBEJ7OHSVZ once bought:  Fairy Tales Tangle Tamer Static Free &nbsp;Detangling Spray for Kids - 12 oz\n",
            "\n",
            "A1WEFBEJ7OHSVZ now bought: Cantu Natural Hair Wave Whip Curling Mousse,8.4 oz\n",
            "\n",
            "Acual bought item is ranked as: 3261 with score: 0.0316\n",
            "------------------------------\n",
            "\n",
            "A1WSZED2O5MA5T once bought: Helen of Troy 1579 Tangle Free Hot Air Brush, White, 3/4 Inch Barrel\n",
            "\n",
            "A1WSZED2O5MA5T now bought: NICKA K Vivid Matte Lipstick NMS07 Black\n",
            "\n",
            "Acual bought item is ranked as: 25702 with score: 0.0\n",
            "------------------------------\n",
            "\n",
            "A28E3FNV1BYC94 once bought: Vibrant Bright Skin Lightening Cream by Healthy Vibes (2 oz) - Skin Whitening Treatment for Birthmarks, Blemishes, Pigmentation - Safe for Sensitive Areas - Natural Ingredients and Hydroquinone Free\n",
            "\n",
            "A28E3FNV1BYC94 now bought: Booty Magic | Butt Enhancement Cream - 2 Month Supply\n",
            "\n",
            "Acual bought item is ranked as: 3603 with score: 0.0286\n",
            "------------------------------\n",
            "\n",
            "A29834GBB4DOP1 once bought: Garnier Whole Blends Coconut Cocoa Butter Shampoo and Conditioner 12 ounces each\n",
            "\n",
            "A29834GBB4DOP1 now bought: Dream Cream Self Preserving 8.4oz\n",
            "\n",
            "Acual bought item is ranked as: 30917 with score: 0.0\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Examples of our testing users\n",
        "\n"
      ],
      "metadata": {
        "id": "1GdvsBz3BDgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o4kG4T3wDB7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}