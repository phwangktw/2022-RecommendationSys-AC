{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session2_Content-based_Recommendation_Algorithm.ipynb.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/phwangktw/data-course-sample/blob/main/Session2_Content_based_Recommendation_Algorithm_ipynb.ipynb",
      "authorship_tag": "ABX9TyMWo1FBrOOix3MVzEnRixh4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phwangktw/data-course-sample/blob/main/Session3_Collaborative-based(surprise_package)_Recommendation_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session3_Collaborative-based(surprise_package)_Recommendation_Algorithm.ipynb"
      ],
      "metadata": {
        "id": "Yz-rghKTyqwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1. Packages import and utiltiets functions\n"
      ],
      "metadata": {
        "id": "h7dsDP9Xyv4K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l7UjSP35yo4j",
        "outputId": "2fd5609f-0adc-4f29-c33c-4d876fd3c6d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1619414 sha256=d162de6b75b286ba0d15150d16cc4749c5973cdcb9a5cc2cdca01dff29a02e2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gzip, json\n",
        "from os.path import exists\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import datetime\n",
        "!pip install surprise\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise import KNNBasic\n",
        "\n",
        "\n",
        "def parse(path):\n",
        "    g = gzip.open(path, 'rb')\n",
        "    for l in g:\n",
        "        yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "    i = 0\n",
        "    df = {}\n",
        "    for d in parse(path):\n",
        "        df[i] = d\n",
        "        i += 1\n",
        "    return pd.DataFrame.from_dict(df, orient='index')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2. Download data"
      ],
      "metadata": {
        "id": "WhNHwYPky2V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv\n",
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_All_Beauty.json.gz\n",
        "\n",
        "metadata = getDF('/content/meta_All_Beauty.json.gz')\n",
        "ratings = pd.read_csv('/content/All_Beauty.csv', names=['asin', 'reviewerID', 'overall', 'unixReviewTime'], header=None)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrM-TOz6y2nx",
        "outputId": "a5f73706-2230-4bd1-bdbe-8abe43e9a2eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-08 23:46:26--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15499476 (15M) [application/octet-stream]\n",
            "Saving to: ‘All_Beauty.csv’\n",
            "\n",
            "All_Beauty.csv      100%[===================>]  14.78M  19.1MB/s    in 0.8s    \n",
            "\n",
            "2022-01-08 23:46:27 (19.1 MB/s) - ‘All_Beauty.csv’ saved [15499476/15499476]\n",
            "\n",
            "--2022-01-08 23:46:27--  http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_All_Beauty.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10329961 (9.9M) [application/octet-stream]\n",
            "Saving to: ‘meta_All_Beauty.json.gz’\n",
            "\n",
            "meta_All_Beauty.jso 100%[===================>]   9.85M  15.1MB/s    in 0.7s    \n",
            "\n",
            "2022-01-08 23:46:28 (15.1 MB/s) - ‘meta_All_Beauty.json.gz’ saved [10329961/10329961]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3. Parsing data"
      ],
      "metadata": {
        "id": "cyt6lpHCzKu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-1: Convert time format"
      ],
      "metadata": {
        "id": "234dDW6TzOnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings['DATE'] = pd.to_datetime(ratings['unixReviewTime'], unit='s')"
      ],
      "metadata": {
        "id": "R2gHgYvNzLAq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-2: Data preprocessing\n",
        "(As same as [session1](https://github.com/phwangktw/data-course-sample/blob/main/Session1_Rule-based_Recommendation_Algorithm.ipynb))\n",
        "\n",
        "*   Dropout the duplicated rows\n",
        "*   Fill the blanks with `nan`\n",
        "*   Parsing the `description` column for generating `rank_num` and `rank_category`\n",
        "*   Regex expression for searching specific key words"
      ],
      "metadata": {
        "id": "hQepuRY9zTAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Cleaning data (cited from: https://github.com/yuchiahung/data-course-sample/blob/main/hw1_Ana.ipynb)\n",
        "##Peaking data firstly\n",
        "metadata_clean = metadata.loc[metadata.astype(str).drop_duplicates().index]\n",
        "metadata_clean.replace('', np.nan, inplace = True)\n",
        "\n",
        "\n",
        "# clean column `rank` -> Parsing out to RankNum + RankCategory\n",
        "metadata_clean['rank'] = metadata_clean['rank'].str.replace('&amp;', '&')\n",
        "metadata_clean['rank'].fillna('0', inplace = True)\n",
        "metadata_clean['rank_category'] = [re.search('in (.*) \\(', r).group(1) if r != '0' else None for r in metadata_clean['rank']]\n",
        "metadata_clean['rank_num'] = [re.search('(.*) in .*', r).group(1) if r != '0' else None for r in metadata_clean['rank']]\n",
        "metadata_clean['rank_num'] = metadata_clean['rank_num'].str.replace(',', '').astype(float)\n",
        "\n",
        "# excluding category != 'Beauty & Personal Care'\n",
        "metadata_clean = metadata_clean[metadata_clean.rank_category == 'Beauty & Personal Care']\n",
        "\n",
        "# convert `price` to float\n",
        "metadata_clean['price'].fillna('0', inplace = True)\n",
        "metadata_clean['price'] = [re.search('\\$(.*)', p).group(1) if re.search('\\$(.*)', p) != None else None for p in metadata_clean['price']]\n",
        "metadata_clean['price'] = metadata_clean['price'].str.replace(',', '').astype(float)\n",
        "\n",
        "# drop useless columns\n",
        "metadata_clean.drop(\n",
        "    ['category', 'tech1', 'fit', 'tech2', 'date', 'similar_item', 'feature', 'main_cat', 'rank'], \n",
        "    axis = 1, \n",
        "    inplace = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If7B5QErzLP6",
        "outputId": "d80a055b-665c-404d-d0d7-67ac4b03427e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3-3: Split time frame for testing and validation purpose"
      ],
      "metadata": {
        "id": "haPjtQk3zaRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_trainings = ratings[\n",
        "    (ratings['DATE'] < '2018-09-01')\n",
        "]\n",
        "ratings_testings = ratings[\n",
        "    (ratings['DATE'] >= '2018-09-01') & \n",
        "    (ratings['DATE'] <= '2018-09-30')\n",
        "]\n",
        "ratings_testings_by_user = ratings_testings.groupby('reviewerID').agg(list).reset_index()[['reviewerID', 'asin']].to_dict('records')\n",
        "ratings_testings_by_user = { rating['reviewerID']: rating['asin'] for rating in ratings_testings_by_user }\n",
        "users = list(ratings_testings_by_user.keys())"
      ],
      "metadata": {
        "id": "Z_EvEzeszLfO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4: Item-based Algorithm Implementation\n",
        "### Step4-1: Generate `dict` format (`user_to_items`)\n",
        "### Step4-2: Filter users with >3 rating history\n",
        "### Step4-3: Generate `pre_user_similarity` dict. (e.g. 'User': {'OtherUsers':[xy xx yy]}\n",
        "### Step4-4: Generate user_similarity"
      ],
      "metadata": {
        "id": "vILVUNMEwtaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommender_suprise(training_data, users=[], k=10, user_based=False, algo=KNNBasic, similarities_module = 'cosine', min_sup = 1):\n",
        "\n",
        "    training_dataBkup = training_data    \n",
        "\n",
        "    # 過濾同個 user 對同個 item 的重複評分資料 (留最新的)\n",
        "    training_data = (\n",
        "        training_data\n",
        "        .sort_values(\"DATE\", ascending=False)\n",
        "        .groupby(['reviewerID', 'asin']).head(1)\n",
        "    )\n",
        "\n",
        "    # use data in the previous year\n",
        "    training_data = training_data[training_data.DATE >= '2017-09-01']\n",
        "\n",
        "    # preparing data\n",
        "    reader = Reader(rating_scale=(0, 5))\n",
        "    training_data = training_data[['reviewerID', 'asin', 'overall']]\n",
        "    data = Dataset.load_from_df(training_data, reader=reader)\n",
        "    \n",
        "    # set the parameters & algorithm\n",
        "    sim_options = {\n",
        "        'name': similarities_module,\n",
        "        'user_based': user_based,   # compute similarities between items\n",
        "        'min_support': 2\n",
        "    }\n",
        "    algo_impl = algo(sim_options=sim_options)\n",
        "    trainset = data.build_full_trainset()\n",
        "    algo_impl.fit(trainset)\n",
        "\n",
        "    # get the recommended items\n",
        "    recommendations = {}\n",
        "    k_rule = 5\n",
        "    for user in users:\n",
        "        items_user_rated = set(training_data.loc[training_data['reviewerID'] == user]['asin'].to_list())\n",
        "        recommend_item_list = []\n",
        "        recommend_item_set = set()\n",
        "        for item in items_user_rated:\n",
        "            iid = algo_impl.trainset.to_inner_iid(item)\n",
        "            recommend_items_iid = algo_impl.get_neighbors(iid, k_rule) # recommend k items based on rated item\n",
        "            for sim_item_iid in recommend_items_iid:\n",
        "                item_raw_id = algo_impl.trainset.to_raw_iid(sim_item_iid)\n",
        "                # if the item has not been rated nor recommended, recommend it\n",
        "                if item_raw_id not in items_user_rated and item_raw_id not in recommend_item_set:\n",
        "                    recommend_item_list.append(item_raw_id)\n",
        "                    recommend_item_set.add(item_raw_id)\n",
        "\n",
        "            if len(recommend_item_list) >= k_rule:\n",
        "                recommend_item_list = recommend_item_list[:k_rule]\n",
        "                break\n",
        "\n",
        "        # Popular products (recommend `k_left` products)\n",
        "        k_left = k - len(recommend_item_list)\n",
        "        ## Best seller (by rating data) & highest rating products (recommend `k` product)\n",
        "        products_rating = training_dataBkup[training_dataBkup.DATE >= '2017-09-01'].groupby('asin')[['overall']].agg(['mean', 'count'])\n",
        "        products_rating.columns = products_rating.columns.droplevel(0)\n",
        "        rule_recom = products_rating.sort_values(by = ['count', 'mean'], ascending = False).index.tolist()[:k_left]\n",
        "        \n",
        "        # concat all the item lists (k2 by rank, k3 by rating, others by sales)\n",
        "        user_recom = recommend_item_list + rule_recom\n",
        "        recommendations[user] = user_recom\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "qK_Crvs--m39"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base Model setup \n",
        "Base case setup as the rule-based algorithm of the most K popular products of the recent year (see as Session1). "
      ],
      "metadata": {
        "id": "P_JbJOsuPUpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rule1: A year-based recommendation\n",
        "def recommender_base(training_data, users=[], k=10):\n",
        "    '''\n",
        "    * training_data: dataframe 輸入的訓練資料集（2018-09-01 以前資料）\n",
        "    * users: [] 需要被推薦的使用者\n",
        "    * k: int 每個使用者需要推薦的商品數\n",
        "    * recommendations: dict\n",
        "      {\n",
        "          使用者一： [推薦商品一, 推薦商品二, ...],\n",
        "          使用者二： [...], ...\n",
        "      }\n",
        "    '''\n",
        "    recommendations = {}\n",
        "    ## Best seller (by rating data) & highest rating products (recommend `k` product)\n",
        "    products_rating = training_data[training_data.DATE >= '2017-09-01'].groupby('asin')[['overall']].agg(['mean', 'count'])\n",
        "    products_rating.columns = products_rating.columns.droplevel(0)\n",
        "    best_seller_lst = products_rating.sort_values(by = ['count', 'mean'], ascending = False).index.tolist()[:k]\n",
        "\n",
        "    recommendations = {user: best_seller_lst for user in users}\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "Jy_4X86r9J8Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Algorithm and the Results"
      ],
      "metadata": {
        "id": "aboqSGJfVBuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(ratings_testings_by_user={}, ratings_by_user={}, method=None):\n",
        "    '''\n",
        "    * ratings_testings_by_user: dict 真實被購買的商品資料（2018-09-01 以後資料）\n",
        "    * ratings_by_user: dict 利用訓練資料學習的推薦商品\n",
        "    * method: str\n",
        "    * score: float\n",
        "    '''\n",
        "    total = 0\n",
        "    for d in ratings_testings_by_user:\n",
        "        if d in ratings_by_user:\n",
        "            total += len(set(ratings_by_user[d]) & set(ratings_testings_by_user[d]))\n",
        "\n",
        "    score = total / len(ratings_testings)\n",
        "    return score\n",
        "\n",
        "ratings_by_user = recommender_suprise(ratings_trainings, users)\n",
        "rcListBase = recommender_base(ratings_trainings, users)\n",
        "\n",
        "\n",
        "score1 = evaluate(ratings_testings_by_user, ratings_by_user)\n",
        "scoreBase = evaluate(ratings_testings_by_user, rcListBase)\n",
        "# Evaluation scores\n",
        "print(f'Rule1: \\n{round(score1, 4)}')\n",
        "print(f'Base_case: \\n{round(scoreBase, 4)}')\n",
        "print(f'Improvemnt of Content-based method: \\n{round(100*(score1-scoreBase)/scoreBase, 1)} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhUWZ2gjPRlR",
        "outputId": "e818ddf1-456a-4a69-890b-b9bbb35f65a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Rule1: \n",
            "0.1\n",
            "Base_case: \n",
            "0.0983\n",
            "Improvemnt of Content-based method: \n",
            "1.7 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5: Discussions of obstacles\n",
        "\n",
        "The reasons that we cannot generate significant score improvements are described as follows:\n",
        "*   Limiting testing users (38/584=6.5%) have purchase (comment) historical records.\n",
        "*   The average content-based score is really low, which reflects that the majority of products the user new bought are irrelated to its history purchased.\n",
        "\n"
      ],
      "metadata": {
        "id": "sED9o2in_Lqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o4kG4T3wDB7a"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}